gcloud auth activate-service-account --key-file=gcloud_key.json && \
    gcloud --quiet config set project dtumlops-detr

gcloud iam service-accounts list

gcloud iam service-accounts list

gcloud iam service-accounts keys create gcloud_key.json --iam-account=1013009768470-compute@developer.gserviceaccount.com

FROM anibali/pytorch:1.10.0-cuda11.3-ubuntu20.04

PROJECT_ID=$(gcloud config list project --format "value(core.project)")
BUCKET_NAME=${PROJECT_ID}-aiplatform
REGION=us-central1
gsutil mb -l $REGION gs://$BUCKET_NAME

export PROJECT_ID=$(gcloud config list project --format "value(core.project)")
export IMAGE_REPO_NAME=detr_pascal
export IMAGE_TAG=latest
export IMAGE_URI=gcr.io/$PROJECT_ID/$IMAGE_REPO_NAME:$IMAGE_TAG

docker build -f trainer.dockerfile -t $IMAGE_URI ./

docker push $IMAGE_URI

export REGION=us-central1
export JOB_NAME=custom_container_job_gpu_$(date +%Y%m%d_%H%M%S)

gcloud ai-platform jobs submit training $JOB_NAME \
  --scale-tier custom \
  --region $REGION \
  --master-image-uri $IMAGE_URI \
  --master-machine-type e2-highmem-16 -- default_root_dir=gs://dtumlops-detr-aiplatform experiment.batch_size=16

  gsutil cp -r gs://dtumlops-detr-aiplatform .

 gcloud builds submit --config cloudbuild.yaml

gcr.io/dtumlops-detr/testing:latest

export REGION=us-central1
export JOB_NAME=custom_container_job_gpu_$(date +%Y%m%d_%H%M%S)

gcloud ai-platform jobs submit training $JOB_NAME \
  --scale-tier custom \
  --region $REGION \
  --master-image-uri gcr.io/dtumlops-detr/testing:latest \
  --master-machine-type e2-highmem \
  -- default_root_dir=gs://dtumlops-detr-aiplatform \
    experiment.batch_size=16 \
    experiment.trainer.limit_val_batches=1.0 \
    experiment.trainer.limit_train_batches=1.0
